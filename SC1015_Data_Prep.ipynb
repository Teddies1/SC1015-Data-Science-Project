{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bddbbb7",
   "metadata": {},
   "source": [
    "# Group Members: Adrian, Aryan, Hon Joo\n",
    "\n",
    "For this project, we have decided to go with a dataset containing 2018 flight data. While 2018 isn't the most up to date data,  data from parts of 2019 and 2020 onwards aren't reliable due to the Covid-19 pandemic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "!pip install missingno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "import time\n",
    "sb.set() # set the default Seaborn style for graphics\n",
    "import missingno as msno \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightdata = pd.read_csv(\"2018.csv\")\n",
    "flightdata_df = pd.DataFrame(flightdata)\n",
    "flightdata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da3e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightdata_df.info(verbose = True, show_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02a2f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We have 7213446  flights in the dataset, which is a hefty amount. We noticed that some of the columns have many missing values. \n",
    "\n",
    "For example, for flights with weather delay (WEATHER_DELAY), there's only 1352710 data points. Although, it is still a significant number.\n",
    "\n",
    "We can use missingno library to visually represent the missing values in each column.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af03dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(flightdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61eff16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We'll check the columns of CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY against ARR_DELAY and DEP_DELAY to see if there any relation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8fa1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = ['CARRIER_DELAY','WEATHER_DELAY','NAS_DELAY','SECURITY_DELAY','LATE_AIRCRAFT_DELAY','ARR_DELAY','DEP_DELAY']\n",
    "\n",
    "# simple function to print out n rows of particular column(s) of a dataframe\n",
    "# requires explicit list of individual column names\n",
    "\n",
    "def printcolumns(dataframe, columnlist, n):\n",
    "    return dataframe[columnlist].head(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e1321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "printcolumns(flightdata_df, datalist, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cccfbc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We picked out 20 data to take a quick look. Naively, it seems like the sum of all the delays equates to ARR_DELAY. This means that the arrival delay is split into the different types of delays that accumulate. \n",
    "\n",
    "We also noticed that some entries in the ARR_DELAY and DEP_DELAY columns are negative. This means that the flights were either on time or early. We want to treat all early flights and on time flights as the same.\n",
    "\n",
    "We will create 2 new columns, ARR_DELAY_NEW and DEP_DELAY_NEW, where any negative value is converted to 0.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d433a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert negative values in a particular column to zeroes and apply it into a new column\n",
    "\n",
    "def negativeToZero(dataframe, newcolumn, inputcolumn):\n",
    "    dataframe[newcolumn] = dataframe[inputcolumn].apply(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e60fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeToZero(flightdata_df,'ARR_DELAY_NEW','ARR_DELAY')\n",
    "negativeToZero(flightdata_df,'DEP_DELAY_NEW','DEP_DELAY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1addbd7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We have successfully converted the negative values in ARR_DELAY and DEP_DELAY to zero and created two new columns containing the cleaned data. From the table below, we can see that negative values have all been converted to zeroes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "negtozerolist = ['ARR_DELAY','ARR_DELAY_NEW','DEP_DELAY','DEP_DELAY_NEW']\n",
    "printcolumns(flightdata_df, negtozerolist, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5f348",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Using .info(), we can see that we have two new columns.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eacc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightdata_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef1252",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We see that the new columns are placed at the 28th and 29th index. \n",
    "\n",
    "To make the dataset cleaner, we should place them after ARR_DELAY and DEP_DELAY.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36446436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to shift a particular column to n-th index of the dataframe\n",
    "\n",
    "def columnshifter(dataframe, n, columnname):\n",
    "    temp_column = dataframe.pop(columnname)\n",
    "    dataframe.insert(n, columnname, temp_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a951e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnshifter(flightdata_df, 15, 'ARR_DELAY_NEW')\n",
    "columnshifter(flightdata_df, 8, 'DEP_DELAY_NEW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c2d3d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flightdata_df.info(verbose = True, show_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(flightdata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a2071",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "After shifting the columns, we can see that ARR_DELAY_NEW and DEP_DELAY_NEW are placed after ARR_DELAY and DEP_DELAY respectively. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e485b",
   "metadata": {},
   "source": [
    "To clean the data further, we chose certain criteria to drop rows by.\n",
    "\n",
    "-no data in arrival delay column\n",
    "\n",
    "-no data in departure delay column\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd45840",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightdata_df = flightdata_df.dropna(subset = ['ARR_DELAY']).reset_index(drop = True)\n",
    "flightdata_df = flightdata_df.dropna(subset = ['DEP_DELAY']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca19758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightdata_df.info(verbose = True, show_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d2039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msno.matrix(flightdata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3149f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now, we have trimmed the dataset slightly to just 7071818 rows. \n",
    "\n",
    "We noticed that the number of CANCELLATION_CODE entries have become zero. It seems that flights without any delay data whatsoever are cancelled flights.\n",
    "\n",
    "We shall explore the columns to check out it's mean/median data to look for outliers. The pertinent columns would be delay data, so we shall look at those. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02483be",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightdata_df[['ARR_TIME','ARR_DELAY_NEW','DEP_DELAY_NEW','DEP_DELAY','CARRIER_DELAY','WEATHER_DELAY','NAS_DELAY','SECURITY_DELAY','LATE_AIRCRAFT_DELAY']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f639e7d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "As we can see, for the row 'max', some of the delays(min) are in the thousands! They would definitely be classed as outliers.\n",
    "\n",
    "We will be removing them during EDA.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f697c1ac",
   "metadata": {},
   "source": [
    "# Encoding categorical data\n",
    "\n",
    "We see that the flight carrier names are abbreviated. We can give names to these abbreviations for easier visualisation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8019084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple func that displays all the unique values of a particular column\n",
    "# returns a list of all unique values of said column\n",
    "\n",
    "def displayUnique(dataframe, column):\n",
    "    outputlist = dataframe[column].unique().tolist()\n",
    "    return outputlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30739038",
   "metadata": {},
   "outputs": [],
   "source": [
    "carrierlist = displayUnique(flightdata_df, 'OP_CARRIER')\n",
    "carrierlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871634e",
   "metadata": {},
   "source": [
    "For readability and reference purposes, we will maintain a dictionary of the full names of each air carrier.\n",
    "\n",
    "Let's also convert the abbrievations of each carrier into their full names, so that the final reference dictionary contains the full name of each carrier mapped to an unique index. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c095a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "carrierdict = {\n",
    "    'UA':'United Airlines',\n",
    "    'AS':'Alaska Airlines',\n",
    "    '9E':'Endeavor Air',\n",
    "    'B6':'JetBlue Airways',\n",
    "    'EV':'ExpressJet',\n",
    "    'F9':'Frontier Airlines',\n",
    "    'G4':'Allegiant Air',\n",
    "    'HA':'Hawaiian Airlines',\n",
    "    'MQ':'Envoy Air',\n",
    "    'NK':'Spirit Airlines',\n",
    "    'OH':'PSA Airlines',\n",
    "    'OO':'SkyWest Airlines',\n",
    "    'VX':'Virgin America',\n",
    "    'WN':'Southwest Airlines',\n",
    "    'YV':'Mesa Airline',\n",
    "    'YX':'Republic Airways',\n",
    "    'AA':'American Airlines',\n",
    "    'DL':'Delta Airlines'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to replace given data in a column to another based on \n",
    "# an input dictionary\n",
    "\n",
    "def replaceEntries(dataframe, column, inputdict):\n",
    "    dataframe[column].replace(inputdict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceEntries(flightdata_df,'OP_CARRIER', carrierdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "carrierlistFULL = displayUnique(flightdata_df, 'OP_CARRIER')\n",
    "carrierlistFULL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a60782",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now that we have our list of full names of the air carriers, now lets generate a dictionary by mapping each one to a unique value.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d88905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to generate a dictionary given an input list. \n",
    "# this function maps each entry in the list into a unique value index\n",
    "# this is because the dataframe columns contains the keys, and we want to replace them with values containing the indexes\n",
    "# if you want the indexes to be on the keys instead then just modify the function slightly\n",
    "\n",
    "def generateDict(inputlist):\n",
    "    values = range(len(inputlist))\n",
    "    outputdict = dict(zip(inputlist, values))\n",
    "    return outputdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2dfd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "carrierindex = generateDict(carrierlistFULL)\n",
    "carrierindex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9bbeb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "With the dictionary generated, now lets replace the air carrier entries in the OP_CARRIER column with the indexes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e199d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceEntries(flightdata_df, 'OP_CARRIER', carrierindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d89bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "carrierlist_replaced = displayUnique(flightdata_df, 'OP_CARRIER')\n",
    "carrierlist_replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec381e4",
   "metadata": {},
   "source": [
    "We can see that the OP_CARRIER column has been replaced by indexes. We can refer to carrierindex dictionary in the future to check which air carrier an index belongs to.\n",
    "\n",
    "\n",
    "Next, we want to simplify the destination and source airport columns as well. We can do this by assigning an index to each invidiual unique column. \n",
    "\n",
    "We can use the same methods that we used on OP_CARRIER on ORIGIN and DEST columns.\n",
    "\n",
    "\n",
    "First, lets explore these columns.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "destlist = displayUnique(flightdata_df, 'DEST')\n",
    "# destlist\n",
    "\n",
    "# uncomment the above to print the list if you want, but its pretty large (300+ unique vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2fcbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "originlist = displayUnique(flightdata_df, 'ORIGIN')\n",
    "# originlist\n",
    "\n",
    "# uncomment the above to print the list if you want, but its pretty large (300+ unique vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867832ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "destDict = generateDict(destlist)\n",
    "originDict = generateDict(originlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# destDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28a607",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "After inspecting both dictionaries, we noticed that both columns are mapped differently. For example, for destDict, 'DEN' is mapped to 0 but for originDict, 'EWR' is mapped to 0.\n",
    "\n",
    "This is because each column has the same amount of unique values, but do not have the exact same entries per row, as origin and destination airports are different.\n",
    "\n",
    "So we shall drop one and only use one as the reference. We shall use destDict for future reference.\n",
    "\n",
    "To avoid confusion, lets rename destDict to airportDict.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6420feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "airportDict = destDict\n",
    "airportDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d38b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceEntries(flightdata_df, 'DEST', airportDict)\n",
    "replaceEntries(flightdata_df, 'ORIGIN', airportDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# destlist_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23fcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originlist_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanitycheck\n",
    "# crosscheck with csv file shows that the origin and dest mapping works\n",
    "flightdata_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20adc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightdata_df.to_csv (r'INPUT PATH HERE', index = False, header=True)\n",
    "\n",
    "# note: change the path name inside the quotation marks to the address where you want the CSV to be exported to.\n",
    "# make sure the imported file ends with (.csv). You can also use .txt if you want.\n",
    "# after running this code snippet the CSV will be downloaded into the path address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf5631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
